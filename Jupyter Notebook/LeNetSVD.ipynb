{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 with SVD\n",
    "Author : Satrya Budi Pratama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist(images_path, labels_path):\n",
    "    \"\"\"\n",
    "        This method load extracted file of MNIST\n",
    "        input : images_path,labels_path\n",
    "        return : features, labels\n",
    "    \"\"\"\n",
    "    \n",
    "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
    "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path,'rb') as imagesFile:\n",
    "        length = len(labels)\n",
    "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
    "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
    "                        .reshape(length, 784) \\\n",
    "                        .reshape(length, 28, 28, 1)\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {}\n",
    "data_train_filename = \"MNIST Dataset/train-images-idx3-ubyte.gz\"\n",
    "data_train_label_filename = \"MNIST Dataset/train-labels-idx1-ubyte.gz\"\n",
    "data_train['X'], data_train['y'] = read_mnist(data_train_filename,data_train_label_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = {}\n",
    "data_test_filename = \"MNIST Dataset/t10k-images-idx3-ubyte.gz\"\n",
    "data_test_label_filename = \"MNIST Dataset/t10k-labels-idx1-ubyte.gz\"\n",
    "data_test['X'], data_test['y'] = read_mnist(data_test_filename, data_test_label_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(position):\n",
    "    image = data_train['X'][position].squeeze()\n",
    "    plt.title('Example %d. Label: %d' % (position, data_train['y'][position]))\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Count\n",
       "0      0   5923\n",
       "1      1   6742\n",
       "2      2   5958\n",
       "3      3   6131\n",
       "4      4   5842\n",
       "5      5   5421\n",
       "6      6   5918\n",
       "7      7   6265\n",
       "8      8   5851\n",
       "9      9   5949"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_count = np.unique(data_train['y'], return_counts=True)\n",
    "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
    "dataframe_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data is balance for each class, it's good for a dataset to build a good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle and split the training data into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling and splitting our training data into 2 sets: train and validation. While leaving the test data unseen by our model until we are done with the training to avoid a self-fulfilling prophecy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "data_train['X'], data_train['y'] = shuffle(data_train['X'], data_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation, 20% of validation data and 80% of training data\n",
    "data_validation = {}\n",
    "data_train['X'], data_validation['X'], data_train['y'], data_validation['y'] = train_test_split(data_train['X'], data_train['y'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of data train\n",
    "len(data_train['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of validation\n",
    "len(data_validation['X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Images \n",
    "The LeNet architecture accepts a 32x32 pixel images as input, mnist data is 28x28 pixels. We simply pad the images with zeros to overcome that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "data_train['X']      = np.pad(data_train['X'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "data_validation['X'] = np.pad(data_validation['X'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "data_test['X']       = np.pad(data_test['X'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(data_train['X'][0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "n_classes = 10\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, AveragePooling2D\n",
    "\n",
    "def lenet5():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.2)) # add this droput to overcame overfitting\n",
    "\n",
    "    model.add(Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model without SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/11\n",
      "18112/48000 [==========>...................] - ETA: 15s - loss: 1.6839 - accuracy: 0.7256"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "model_without_svd = lenet5()\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model_without_svd.compile(optimizer= optimizer, \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "original = model_without_svd.fit(x=data_train['X'],y=data_train['y'], epochs=11,  \n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(data_validation['X'], data_validation['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "# list all data in history\n",
    "print(original.history.keys())\n",
    "# summarize history for accuracy\n",
    "x_axis = np.arange(1,EPOCHS+1)\n",
    "plt.plot(x_axis,original.history['accuracy'])\n",
    "plt.plot(x_axis,original.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(x_axis,original.history['loss'])\n",
    "plt.plot(x_axis,original.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model without SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.evaluate(data_test['X'], data_test['y'])\n",
    "print(\"Model Loss : {:.4f} - Accuracy : {:.4f}\".format(test_result[0],test_result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_data(features, number_of_components):\n",
    "    \"\"\"\n",
    "    This method process all original data to low rank data using SVD, and reconstruct using some components.\n",
    "    Result of the dimension of features is same, so no dimension reduction but keep the data lower.\n",
    "    Input : features , number_of_components\n",
    "    Output : reduced_features\n",
    "    \"\"\"\n",
    "    \n",
    "    reduced_features = []\n",
    "    # iterate over features\n",
    "    for i in range(len(features)):\n",
    "        # obtain svd without the channel 32x32xC\n",
    "        U, S, V = np.linalg.svd(features[i].squeeze())\n",
    "        # construct the matrix to lower rank\n",
    "        reduced_feature = U[:, :number_of_components] @ np.diag(S[:number_of_components]) @ V[:number_of_components , :]\n",
    "        # append to the list and add channel again so 32x32x1\n",
    "        reduced_features.append(reduced_feature[:,:,np.newaxis]) \n",
    "    \n",
    "    return np.array(reduced_features) # convert from list to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Image from reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components that we use, less than the original dimension\n",
    "num_of_components = 6\n",
    "\n",
    "# get SVD\n",
    "U, S, V = np.linalg.svd(data_train['X'][0].squeeze())\n",
    "# reconstruct the matrix to low rank matrix with 15 components \n",
    "low_rank = U[:, :num_of_components] @ np.diag(S[:num_of_components]) @ V[:num_of_components, :]\n",
    "low_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "plt.imshow(low_rank.squeeze(), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "display_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reduced data for Data Training, Data Validation, and Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_SVD = get_reduced_data(data_train['X'], num_of_components)\n",
    "data_test_SVD = get_reduced_data(data_test['X'], num_of_components)\n",
    "data_validation_SVD = get_reduced_data(data_validation['X'], num_of_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_svd = lenet5()\n",
    "model_svd = model_with_svd.fit(x=data_train_SVD,y=data_train['y'], epochs=EPOCHS,  \n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(data_validation_SVD, data_validation['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "# list all data in history\n",
    "print(model_svd.history.keys())\n",
    "# summarize history for accuracy\n",
    "x_axis = np.arange(1,EPOCHS+1)\n",
    "plt.plot(x_axis,model_svd.history['accuracy'])\n",
    "plt.plot(x_axis,model_svd.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(x_axis,model_svd.history['loss'])\n",
    "plt.plot(x_axis,model_svd.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model_with_svd.evaluate(data_test_SVD, data_test['y'])\n",
    "print(\"Model Loss : {:.4f} - Accuracy : {:.4f}\".format(test_result[0],test_result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the number of components to test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_list = []\n",
    "required_time_list = []\n",
    "num_of_components_list = np.arange(2,32,2)\n",
    "num_of_components_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_svd = lenet5()\n",
    "for num_components in num_of_components_list:\n",
    "    print(\"\\n\")\n",
    "    print(\"SVD Implementation with components {}\".format(num_components))\n",
    "    start_time = time.time()\n",
    "    print(\"Preprocessing all data...\")\n",
    "    # pre processing\n",
    "    data_train_SVD = get_reduced_data(data_train['X'], num_components)\n",
    "    data_test_SVD = get_reduced_data(data_test['X'], num_components)\n",
    "    data_validation_SVD = get_reduced_data(data_validation['X'], num_components)\n",
    "    print(\"Training model...\")\n",
    "    # training\n",
    "    model_with_svd.fit(x=data_train_SVD,y=data_train['y'], epochs=EPOCHS,  \n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(data_validation_SVD, data_validation['y']))\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    # testing\n",
    "    test_result = model_with_svd.evaluate(data_test_SVD, data_test['y'])\n",
    "    print(\"Model Loss : {:.4f} - Accuracy : {:.4f}\".format(test_result[0],test_result[1]))\n",
    "    required_time = time.time() - start_time\n",
    "    print(\"--- %s seconds ---\" % (required_time))\n",
    "    acc_test_list.append(test_result[1]) # append accuracy result to list\n",
    "    required_time_list.append(required_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_of_components_list,acc_test_list)\n",
    "plt.title('Accuracy on Testing Data SVD')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18 number components of SVD gives the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
